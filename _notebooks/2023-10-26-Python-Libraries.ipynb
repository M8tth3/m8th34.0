{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "toc: true\n",
    "comments: true\n",
    "layout: post\n",
    "title: Student Lesson Python Libraries\n",
    "tags: [hacks]\n",
    "categories: [CSP, Week 10] \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is a Library?\n",
    "Essentially a list of pre-written code that you can use to streamline and clean up your program.\n",
    "\n",
    "Libraries can help simplify complex programs\n",
    "\n",
    "APIS are specifications for how the procedures in a library behave, and how they can be used \n",
    "\n",
    "Documentations for an API/library is necessary in understanding the behaviors provided by the API/library and how to use them\n",
    "\n",
    "Libraries that we will go over: Requests, Pillow, Pandas, Numpy, Scikit-Learn, TensorFlow, matplotlib.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Required Installations\n",
    "Please run the following commands in your vscode terminal in order to continue the lesson\n",
    "- pip install numpy\n",
    "- pip install matplotlib\n",
    "- pip install scikit-learn\n",
    "- pip install pillow\n",
    "- pip install pandas\n",
    "- pip install tensorflow\n",
    "- pip install requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Images using requests and pillow libraries\n",
    "'Requests' is focused on handling HTTP requests and web data while 'Pillow' is designed for data manipulation and analysis\n",
    "It's common to see them used together in data-related assignments where data is fetched by HTTP requests using Requests and then processed and analyzed with Pandas.\n",
    "\n",
    "Here's an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "# Step 1: Download an image using Requests\n",
    "image_url = \"https://example.com/path/to/your/image.jpg\"  # Replace with the actual URL of the image you want to download\n",
    "response = requests.get(image_url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    # Step 2: Process the downloaded image using Pillow\n",
    "    image_data = BytesIO(response.content)  # Create an in-memory binary stream from the response content\n",
    "    img = Image.open(image_data)  # Open the image using Pillow\n",
    "\n",
    "    # Perform image processing tasks here, like resizing or applying filters\n",
    "    img = img.resize((x, y))  # Resize the image and replace x,y with desired amounts\n",
    "\n",
    "    # Step 3: Save the processed image using Pillow\n",
    "    img.save(\"processed_image.jpg\")  # Save the processed image to a file\n",
    "\n",
    "    print(\"Image downloaded, processed, and saved.\")\n",
    "else:\n",
    "    print(f\"Failed to download image. Status code: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this code, we use the Requests library to download an image from a URL and then if the download is successful the HTTP status code 200 will pop up, and from there we create an in-memory binary stream (BytesIO) from the response content. We then use the Pillow library to open the image, make any necessary changes, and save the processed image to a file.\n",
    "\n",
    "Here's a step by step tutorial on how we wrote this code: \n",
    "1)We started by importing the necessary libraries, which were Requests, Pillow, and io.\n",
    "\n",
    "2)Download the Image\n",
    "\n",
    "3)Use the Requests library to send an HTTP GET request to the URL to download the image.\n",
    "Check the response status code to make sure the download goes through(status code 200).\n",
    "\n",
    "4)If the download is successful, create an in-memory binary stream (BytesIO) from the response content.\n",
    "Process the Image:\n",
    "\n",
    "5)Utilize the Pillow library to open the image from the binary stream.\n",
    "Change photo to desired preference(ie: size)\n",
    "Save the Processed Image:\n",
    "\n",
    "6)Save the processed image to a file using Pillow. Choose a filename and file format for the saved image.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hack 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a Python code that accomplishes the following tasks:\n",
    "\n",
    "Downloads an image from a specified URL using the Requests library.\n",
    "Processes the downloaded image (like resizing) using the Pillow library.\n",
    "Save the processed image to a file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "# Step 1: Download a random image using Requests\n",
    "image_url = \"https://source.unsplash.com/random\"  # Use a source that provides random images\n",
    "response = requests.get(image_url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    # Step 2: Process the downloaded image using Pillow\n",
    "    image_data = BytesIO(response.content)  # Create an in-memory binary stream from the response content\n",
    "    img = Image.open(image_data)  # Open the image using Pillow\n",
    "\n",
    "    # Perform image processing tasks here, like resizing or applying filters\n",
    "    img = img.resize((200, 400))  # Resize the image and replace with desired dimensions\n",
    "\n",
    "    img.save(\"processed_image.jpg\")  # Save the processed image to a file\n",
    "\n",
    "    print(\"Random image downloaded, processed, and saved.\")\n",
    "else:\n",
    "    print(f\"Failed to download image. Status code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Math Operations With Python Libraries\n",
    "Numpy(Numerical Python) is used for numerical and scientific computing. It provides tools for handling large sets of numbers, such as data tables and arrays. Numpy makes it easier and more efficient to do mathematical tasks. \n",
    "\n",
    "The Matplotlib library lets you create a visual representation of your data (graphs, charts, and etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Sine Graph\n",
    "Uses numpy and matplotlib libaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate sample data with NumPy\n",
    "x = np.linspace(0, 2 * np.pi, 100) \n",
    "# Create an array of values from 0 to 2*pi\n",
    "# 100 is included to have 100 points distributed between 0 and 2Ï€ to make graph smoother\n",
    "y = np.sin(x)\n",
    "# Compute the sine of each value\n",
    "\n",
    "# Create a simple line plot using Matplotlib\n",
    "plt.plot(x, y, label='Sine Function', color='blue', linestyle='-')  # Create the plot\n",
    "plt.title('Sine Function')  # Set the title\n",
    "plt.xlabel('x')  # Label for the x-axis\n",
    "plt.ylabel('sin(x)')  # Label for the y-axis\n",
    "plt.grid(True)  # Display a grid\n",
    "plt.legend()  # Show the legend\n",
    "plt.show()  # Display the plot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hack 2\n",
    "Using the data from the numpy library, create a visual graph using different matplotlib functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate data for the line\n",
    "x = np.linspace(0, 10, 50)  # Create an array of values from 0 to 10\n",
    "y1 = 2 * x + 1  # Set of data points for the line\n",
    "\n",
    "# Create and display a plot using Matplotlib\n",
    "plt.plot(x, y1, label='Linear Graph', color='red', linestyle='-')  # Create the plot\n",
    "plt.title('Line')  # Set the title\n",
    "plt.xlabel('x')  # Label for the x-axis\n",
    "plt.ylabel('2x + 1')  # Label for the y-axis\n",
    "plt.grid(True)  # Display a grid\n",
    "plt.legend()  # Show the legend\n",
    "plt.show()  # Display the plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensor Flow is used in deep learning and neural networks, while scikit-learn is used for typical machine learning tasks. When used together, they can tackle machine learning projects. In the code below, Tensor Flow is used for model creation and training. Scikit-learn is used for data-processing and model evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pip install tensorflow scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "# Generate synthetic data\n",
    "np.random.seed(0)\n",
    "X = np.random.rand(100, 1)  # Feature\n",
    "y = 2 * X + 1 + 0.1 * np.random.randn(100, 1)  # Target variable with noise\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "# Create a simple linear regression model using TensorFlow and Keras\n",
    "model = keras.Sequential([\n",
    "    layers.Input(shape=(1,)),\n",
    "    layers.Dense(1)\n",
    "])\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=32, verbose=2)\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "# Calculate the Mean Squared Error on the test set\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Error: {mse:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A decrease in loss and time metrics (ms/epoch and ms/step) shows the efficiency increases as the training epochs increases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hack\n",
    "fill in the missing code to match the custom data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Generate a custom dataset\n",
    "np.random.seed(0)\n",
    "num_samples = 100\n",
    "bedrooms = np.random.randint(1, 5, num_samples)\n",
    "square_footage = np.random.randint(1000, 2500, num_samples)\n",
    "house_prices = 100000 + 50000 * bedrooms + 100 * square_footage + 10000 * np.random.randn(num_samples)\n",
    "X = np.column_stack((bedrooms, square_footage))\n",
    "y = house_prices.reshape(-1, 1)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Create a regression model using TensorFlow and Keras\n",
    "model = keras.Sequential([\n",
    "    layers.Input(shape=(2,)),  # Input shape adjusted to the number of features\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(1)  # Output layer for regression\n",
    "])\n",
    "\n",
    "# Compile the model for regression\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=32, verbose=0)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate the Mean Squared Error on the test set\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Error on the test set: {mse:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HOMEWORK 1\n",
    "\n",
    "Create a GPA calculator using Pandas and Matplot libraries and make:\n",
    "1) A dataframe\n",
    "2) A specified dictionary\n",
    "3) and a print function that outputs the final GPA\n",
    "\n",
    "Extra points can be earned with creativity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Pandas library\n",
    "import pandas as pd\n",
    "\n",
    "# Import the Matplotlib library \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a dictionary 'data' containing course information\n",
    "data = {\n",
    "    'Course': ['Humanities', 'CSP', 'World', 'Math', 'Spanish'],\n",
    "    'Credits': [3, 3, 4, 2, 2],\n",
    "    'Grade': ['A', 'A', 'B', 'A', 'A'],\n",
    "}\n",
    "\n",
    "# Create a Pandas DataFrame 'df' from the 'data' dictionary\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Create a dictionary 'grade_points' to map letter grades to grade points\n",
    "grade_points = {\n",
    "    'A': 4.0,\n",
    "    'B': 3.0,\n",
    "    'C': 2.0,\n",
    "    'D': 1.0,\n",
    "    'F': 0.0,\n",
    "}\n",
    "\n",
    "# Add a new column 'Grade Points' to the DataFrame 'df' based on the 'Grade' column\n",
    "df['Grade Points'] = df['Grade'].map(grade_points)\n",
    "\n",
    "# Calculate the total grade points by multiplying 'Grade Points' and 'Credits' columns and summing them\n",
    "total_grade_points = (df['Grade Points'] * df['Credits']).sum()\n",
    "\n",
    "# Calculate the total credits by summing the 'Credits' column\n",
    "total_credits = df['Credits'].sum()\n",
    "\n",
    "# Calculate the GPA by dividing the total grade points by the total credits\n",
    "gpa = total_grade_points / total_credits\n",
    "\n",
    "# Create a bar chart to visualize the 'Grade Points' for each course\n",
    "plt.bar(df['Course'], df['Grade Points'])\n",
    "plt.xlabel('Course')\n",
    "plt.ylabel('Grade Points')\n",
    "plt.title('Course Grade Points')\n",
    "\n",
    "# Display the bar chart\n",
    "plt.show()\n",
    "\n",
    "def print_final_gpa(gpa):\n",
    "    print(f'Your GPA is {gpa:.2f} this trimester')\n",
    "\n",
    "print_final_gpa(gpa) # print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HOMEWORK 2\n",
    "\n",
    "Import and use the \"random\" library to generate 50 different points from the range 0-100, then display the randomized data using a scatter plot.\n",
    "\n",
    "Extra points can be earned with creativity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate 50 random data points in the range of 0-100 for x and y coordinates\n",
    "xCoords = [random.randint(0, 100) for _ in range(50)]\n",
    "yCoords = [random.randint(0, 100) for _ in range(50)]\n",
    "\n",
    "# Create a scatter plot\n",
    "plt.scatter(xCoords, yCoords, c='b', marker='o')\n",
    "\n",
    "# Add labels and a title to the plot\n",
    "plt.xlabel('X-axis')\n",
    "plt.ylabel('Y-axis')\n",
    "plt.title('Random Data Scatter Plot')\n",
    "\n",
    "# each dot diff color (muy creative)\n",
    "for x, y in zip(xCoords, yCoords):\n",
    "    color = \"#{:02x}{:02x}{:02x}\".format(random.randint(0, 255), random.randint(0, 255), random.randint(0, 255))\n",
    "    plt.scatter(x, y, c=color, marker='o', s=50)\n",
    "\n",
    "# Display the plot\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
